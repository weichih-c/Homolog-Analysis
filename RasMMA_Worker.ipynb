{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reverse clusterID by hooklogName\n",
    "\n",
    "def findClusterID(nameDict, hooklogName):\n",
    "    for key, value in nameDict.items():\n",
    "        if(value == hooklogName):\n",
    "            return key\n",
    "    return hooklogName\n",
    "\n",
    "def getInitialNameDict(initialDict):\n",
    "    nameDict = dict()\n",
    "    for key, value in initialDict.items():\n",
    "        name = value[0]\n",
    "        nameDict[key] = name\n",
    "    return nameDict\n",
    "\n",
    "# convert memberSet to List type\n",
    "\n",
    "def getMemberList(memberSet, nameDict):\n",
    "    memberList = list()\n",
    "    while(len(memberSet)>0):\n",
    "        member = memberSet.pop()\n",
    "        clusterID = findClusterID(nameDict, member)\n",
    "        memberList.append(clusterID)\n",
    "    return memberList\n",
    "\n",
    "# z[0] = g1,  z[1] = g2,  z[2] = 高度\n",
    "# Create structure Z\n",
    "\n",
    "def createStructZ(intermediate_dict, nameDict):\n",
    "    import numpy as np\n",
    "    Z = np.zeros((len(intermediate_dict) ,4))\n",
    "    \n",
    "    intermediate_list = sorted(intermediate_dict.items(), key=lambda x:x[0])\n",
    "    \n",
    "    iterCounter = 0\n",
    "    for item in intermediate_list:\n",
    "        value = item[1] # get original dict value\n",
    "        score = value[0]\n",
    "        height = 1 - score # get cluster distance\n",
    "        clusterName = value[1][0]\n",
    "        memberSet = value[2] # members set\n",
    "        memberList = getMemberList(memberSet, nameDict)\n",
    "        print(clusterName, \" : \", memberList)\n",
    "        member1 = memberList[0][1::]\n",
    "        member2 = memberList[1][1::]\n",
    "        \n",
    "        Z[iterCounter] = [member1, member2, height, len(memberList)] # set Z element\n",
    "        iterCounter+=1\n",
    "        \n",
    "    return Z\n",
    "\n",
    "def createLabelList(nameDict):\n",
    "    dict_keys = list(nameDict.keys())\n",
    "    dict_keys.sort(key=lambda tup: int(tup[1::] )) # sort keys by number in clusterName (i.e., '31' in 'G31')\n",
    "    \n",
    "    labelList = list()\n",
    "    for key in dict_keys:\n",
    "        labelList.append( nameDict[key] )\n",
    "    \n",
    "    return labelList\n",
    "\n",
    "# do clustering and output two pickle files. (@_intermediate.pickle and @_nameDict.pickle)\n",
    "% run RasMMA.ipynb\n",
    "import os\n",
    "\n",
    "def startClustering(data_directory, tag, outputPath, thresholdValue=None):\n",
    "    \n",
    "    if not os.listdir(data_directory):\n",
    "        print(\"Data Empty\")\n",
    "        return\n",
    "    \n",
    "    # Create Directories if didn't exist\n",
    "    if not os.path.isdir(outputPath): os.makedirs(outputPath)\n",
    "    if not os.path.isdir(pickleDir): os.makedirs(pickleDir)\n",
    "    \n",
    "    intermediatePool, initialDict, roundInfos, residual = do_RasMMA_clustering(data_directory, tag, outputPath, thresholdValue)\n",
    "\n",
    "    # saving intermediatePool as pickle file\n",
    "    with open(pickleDir + tag + '_intermediate.pickle', 'wb') as handle:\n",
    "        pickle.dump(intermediatePool, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # saving initialNames dict as pickle file\n",
    "    with open(pickleDir + tag + '_initialDict.pickle', 'wb') as handle:\n",
    "        pickle.dump(initialDict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    # saving round information dict as pickle file\n",
    "    with open(pickleDir + tag + '_roundInfos.pickle', 'wb') as handle:\n",
    "        pickle.dump(roundInfos, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    if(residual is not None):\n",
    "        # saving round information dict as pickle file\n",
    "        with open(pickleDir + tag + '_residual.pickle', 'wb') as handle:\n",
    "            pickle.dump(residual, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_reporting(pickleDir, tag, outputPath):\n",
    "    import pickle\n",
    "\n",
    "    # read the results from pickle files\n",
    "    with open(pickleDir + tag + '_intermediate.pickle', 'rb') as handle:\n",
    "        intermediate = pickle.load(handle)\n",
    "    with open(pickleDir + tag + '_initialDict.pickle', 'rb') as handle:\n",
    "        initialDict = pickle.load(handle)\n",
    "    with open(pickleDir + tag + '_roundInfos.pickle', 'rb') as handle:\n",
    "        roundInfos = pickle.load(handle)\n",
    "\n",
    "    # calculate motif lengths of all common motifs\n",
    "    def getMotifsLengthList(motifs):\n",
    "        motifLens = list()\n",
    "        for motif in motifs:\n",
    "            mLen = len(motif)\n",
    "            motifLens.append(mLen)\n",
    "        return motifLens\n",
    "\n",
    "    def findGeneratedRoundNumber(clusterName, roundInfosDict):\n",
    "        for key, value in roundInfosDict.items():\n",
    "            if clusterName in value:\n",
    "                return key\n",
    "        return -1\n",
    "\n",
    "    import csv\n",
    "\n",
    "    descendant_dict = dict()\n",
    "    groupInfo_list = list()\n",
    "    groupMotif_dict = dict()\n",
    "\n",
    "    intermediate_list = sorted(intermediate.items(), key=lambda x : x[0])\n",
    "    for item in intermediate_list:\n",
    "        value = item[1] # get original dict value\n",
    "        score = value[0]\n",
    "        clusterName = value[1][0]\n",
    "        memberSet = value[2]\n",
    "        motifs = value[1][1]\n",
    "\n",
    "        # calculate motif lengths of all common motifs\n",
    "        motifsLens = getMotifsLengthList(motifs) # is a list of numbers\n",
    "        totalMotifLen = sum(motifsLens) # sum the list\n",
    "\n",
    "        motifsCount = len(motifs)\n",
    "\n",
    "        descendants = set()\n",
    "        for member in memberSet:\n",
    "            if member[0] == \"G\":\n",
    "                for descendant in descendant_dict[member]:\n",
    "                    descendants.add(descendant)\n",
    "            else:\n",
    "                descendants.add(member)\n",
    "\n",
    "        descendant_dict[clusterName] = descendants\n",
    "\n",
    "\n",
    "        groupMotif_dict[clusterName] = motifs\n",
    "        roundNumber = findGeneratedRoundNumber(clusterName, roundInfos)\n",
    "        groupInfo_list.append((roundNumber, clusterName, score, memberSet, motifsCount, motifsLens, totalMotifLen))\n",
    "\n",
    "    with open(pickleDir + tag + \"_descendant.pickle\", 'wb') as f:\n",
    "        pickle.dump(descendant_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # write file \"GroupInfo.csv\" :  clusterName, score, members, motifCount, common motifs length list\n",
    "    with open(outputPath + tag + \"_GroupInfo.csv\", 'w', newline='') as infoFile:\n",
    "        spamwriter = csv.writer(infoFile, delimiter=',',\n",
    "                                quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        header = [\"Round\", \"ClusterName\", \"SimilarityScore\", \"Members\", \"MotifsCount\", \"Motifs_Length\", \"Total_MotifLength\"]\n",
    "        spamwriter.writerow(header)\n",
    "\n",
    "        # write initial cluster informations(i.e., hooklogs)\n",
    "        for key in sorted(initialDict.keys(), key = lambda x : int(x[1::])):\n",
    "            # something like this: (0, \"G1\", \"N/A\", \"abc\", 1, 109)\n",
    "            originDataRow = (0, key, \"N/A\", initialDict[key][0], 1, initialDict[key][1], initialDict[key][1])\n",
    "            spamwriter.writerow(originDataRow)\n",
    "\n",
    "        # write cluster informations\n",
    "        for group in groupInfo_list:\n",
    "            spamwriter.writerow(group)\n",
    "\n",
    "    with open(outputPath + tag + \"_Descendants.csv\", \"w\", newline='') as descFile:\n",
    "        spamwriter = csv.writer(descFile, delimiter=',',\n",
    "                                quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        header = [\"ClusterName\", \"Descendant Counts\", \"Descendants\"]\n",
    "        spamwriter.writerow(header)\n",
    "        for key in sorted(descendant_dict.keys(), key = lambda x : int(x[1::])):\n",
    "            row = (key, len(descendant_dict[key]), descendant_dict[key])\n",
    "            spamwriter.writerow(row)\n",
    "\n",
    "    # write file \"Motifs.csv\" :  clusterName, MotifNumber, apis\n",
    "    with open(outputPath + tag + \"_Motifs.csv\", 'w', newline='', encoding='utf-8') as motifFile:\n",
    "        spamwriter = csv.writer(motifFile, delimiter=',',\n",
    "                                quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        header = [\"ClusterName\", \"MotifIndex\", \"MotifLength\", \"Common Motif APIs\"]\n",
    "        spamwriter.writerow(header)\n",
    "\n",
    "        for key in sorted(groupMotif_dict.keys(), key = lambda x : int(x[1::])):\n",
    "            group_motifs = groupMotif_dict[key]\n",
    "            motifIdx = 0\n",
    "            for motif in group_motifs:\n",
    "                firstMotifAPI = True\n",
    "                motifLen = len(motif)\n",
    "                for api in motif:\n",
    "                    if(firstMotifAPI):\n",
    "                        row = (key, motifIdx, motifLen, api)\n",
    "                        firstMotifAPI = False\n",
    "                    else:\n",
    "                        row = (\"\", \"\", \"\", api)\n",
    "                    spamwriter.writerow(row)\n",
    "                motifIdx += 1\n",
    "\n",
    "    # output residual information of SBBGCA\n",
    "\n",
    "    with open(pickleDir + tag + '_residual.pickle', 'rb') as handle:\n",
    "        residual = pickle.load(handle)\n",
    "\n",
    "    with open(outputPath + tag + \"_GroupInfo.csv\", 'a', newline='') as expandGroupInfo:\n",
    "        spamwriter = csv.writer(expandGroupInfo, delimiter=',',\n",
    "                                quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        header = [\"ClusterName\", \"Members\", \"MotifLength\"]\n",
    "\n",
    "        spamwriter.writerow(\"\")\n",
    "        spamwriter.writerow((\"Residual Clusters:\",\"\",\"\"))\n",
    "        spamwriter.writerow(header)\n",
    "\n",
    "        for key, value in residual.items():\n",
    "            clusterName = value[0][0]\n",
    "            motifsList = value[0][1]\n",
    "            motifLens = getMotifsLengthList(motifsList)\n",
    "            members = value[1]\n",
    "            if( len(members) == 0 ):\n",
    "                row = (clusterName, \"N/A\", motifLens)\n",
    "            else:\n",
    "                row = (clusterName, members, motifLens)\n",
    "\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Family -  berbew  ===\n",
      "-- Finish Initializing --\n",
      "-- Start Clustering --\n",
      "Threshold set = 0.7\n",
      "Round:  1\n",
      "ScoreList Length in method :  210\n",
      "generatedSeqNum now:  27\n",
      "Round:  2\n",
      "ScoreList Length in method :  105\n",
      "generatedSeqNum now:  29\n",
      "Round:  3\n",
      "ScoreList Length in method :  66\n",
      "generatedSeqNum now:  30\n",
      "Round:  4\n",
      "ScoreList Length in method :  55\n",
      "generatedSeqNum now:  31\n",
      "Round:  5\n",
      "ScoreList Length in method :  45\n",
      "generatedSeqNum now:  31\n",
      "-- Finish Clustering --\n",
      "-- Clean Temp Pickle Files --\n",
      "=== Family -  berbew  Finished ===\n"
     ]
    }
   ],
   "source": [
    "# basic global inputs variable\n",
    "\n",
    "manualThresholdNumber = 0.7 # defined the threshold of merge score\n",
    "\n",
    "base_dir = \"11939data/myMismatchLonerTest/\"\n",
    "output_base = \"output/myMismatchLonerTest/\"\n",
    "\n",
    "skipFam = {''}\n",
    "\n",
    "for familyName in os.listdir(base_dir):\n",
    "    if familyName + '_' + str(manualThresholdNumber) in os.listdir(output_base) or familyName in skipFam:\n",
    "        continue\n",
    "    fam_data_dir = base_dir + familyName + '/'\n",
    "    tag = familyName + \"_\" + str(manualThresholdNumber) # used for pickle name\n",
    "\n",
    "    outputPath = output_base + tag + \"/\"\n",
    "    pickleDir = outputPath + \"pickle/\"\n",
    "    print(\"=== Processing Family - \", familyName , \" ===\")\n",
    "    startClustering(fam_data_dir, tag, outputPath, manualThresholdNumber)\n",
    "    output_reporting(pickleDir, tag, outputPath)\n",
    "    print(\"=== Family - \", familyName , \" Finished ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use for cross family (a.k.a BegC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "%run CollectForestInfo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = 'output/top3_party_0622/'\n",
    "\n",
    "tag = '28fam_cross'\n",
    "\n",
    "outputPath = 'output/begC/'+tag+'/'\n",
    "\n",
    "famNames = os.listdir(base_dir)\n",
    "\n",
    "cand_clusters = dict()\n",
    "candCounter = 0\n",
    "for fName in famNames:\n",
    "    pickleDir = base_dir+fName+'/pickle/'\n",
    "    interPkl = pickleDir + fName + \"_intermediate.pickle\"\n",
    "    residualPkl = pickleDir + fName + \"_residual.pickle\"\n",
    "\n",
    "    forestInfo = CollectForestInfo(interPkl,\n",
    "                           residualPkl,\n",
    "                           True) # one pickle is a forest\n",
    "\n",
    "    for treeName in forestInfo.getTreeRootNameList():\n",
    "        labelName = fName+'_'+treeName\n",
    "        memberCount = len(forestInfo.getTreeMembers(treeName))\n",
    "        repSeq = forestInfo.getRepAPISeq(treeName)\n",
    "        if memberCount > 2 and len(repSeq) > 10:\n",
    "            clusterName = 'G'+str(candCounter)\n",
    "            R = (clusterName, [repSeq])\n",
    "#             R = (clusterName, [(repSeq, 0, len(repSeq)-1)] )\n",
    "            clusterMembers = set()\n",
    "            clusterMembers.add(labelName)\n",
    "            cand_clusters[candCounter] = (R, clusterMembers)\n",
    "            candCounter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intermediatePool, initialDict, roundInfos, residual = clusterInitializedReps(cand_clusters, tag, outputPath, 0.8)\n",
    "\n",
    "pickleDir = outputPath + 'pickle/'\n",
    "if not os.path.isdir(pickleDir): os.makedirs(pickleDir)\n",
    "\n",
    "# saving intermediatePool as pickle file\n",
    "with open(pickleDir + tag + '_intermediate.pickle', 'wb') as handle:\n",
    "    pickle.dump(intermediatePool, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# saving initialNames dict as pickle file\n",
    "with open(pickleDir + tag + '_initialDict.pickle', 'wb') as handle:\n",
    "    pickle.dump(initialDict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# saving round information dict as pickle file\n",
    "with open(pickleDir + tag + '_roundInfos.pickle', 'wb') as handle:\n",
    "    pickle.dump(roundInfos, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "if(residual is not None):\n",
    "    # saving round information dict as pickle file\n",
    "    with open(pickleDir + tag + '_residual.pickle', 'wb') as handle:\n",
    "        pickle.dump(residual, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
